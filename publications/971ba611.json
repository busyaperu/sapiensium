{"id": "971ba611", "examenData": {"examen_id": "120139", "nombre_examen": "Arquitecturas Reactivas", "tipo_examen": "Practica", "fecha": "2025-05-08T14:22:11.600Z", "nombre_profesor": "Mariela Isabel Camargo Rom\u00e1n", "profesor_id": "16MI987", "preguntas_marcar": [{"numero": 1, "texto": "En una arquitectura reactiva, \u00bfqu\u00e9 significa el principio de Responsiveness?\nA) El sistema responde r\u00e1pidamente a fallos.\nB) El sistema se mantiene \u00e1gil bajo carga variable.\nC) El sistema responde de forma oportuna si es posible.\nD) El sistema se basa en la comunicaci\u00f3n s\u00edncrona.\nE) El sistema limita la concurrencia para mejorar el rendimiento.", "puntaje": 0.5, "opciones": [{"texto": "Opci\u00f3n A", "valor": "A"}, {"texto": "Opci\u00f3n B", "valor": "B"}, {"texto": "Opci\u00f3n C", "valor": "C"}, {"texto": "Opci\u00f3n D", "valor": "D"}, {"texto": "Opci\u00f3n E", "valor": "E"}], "respuestaSeleccionada": null, "respuestaCorrectaIndex": 3}, {"numero": 2, "texto": "\u00bfQu\u00e9 principio de la arquitectura reactiva se relaciona con la capacidad del sistema para recuperarse de fallos y mantenerse disponible?\nA) Elasticity\nB) Responsiveness\nC) Message-Driven\nD) Resilience\nE) Scalability", "puntaje": 0.5, "opciones": [{"texto": "Opci\u00f3n A", "valor": "A"}, {"texto": "Opci\u00f3n B", "valor": "B"}, {"texto": "Opci\u00f3n C", "valor": "C"}, {"texto": "Opci\u00f3n D", "valor": "D"}, {"texto": "Opci\u00f3n E", "valor": "E"}], "respuestaSeleccionada": null, "respuestaCorrectaIndex": 1}, {"numero": 3, "texto": "\u00bfCu\u00e1l es el mecanismo de comunicaci\u00f3n fundamental en un sistema reactivo Message-Driven?\nA) Llamadas a procedimientos remotos s\u00edncronas.\nB) Intercambio de datos a trav\u00e9s de bases de datos compartidas.\nC) Comunicaci\u00f3n as\u00edncrona basada en el paso de mensajes.\nD) Llamadas a API REST s\u00edncronas.\nE) Uso exclusivo de colas de mensajes persistentes.", "puntaje": 0.5, "opciones": [{"texto": "Opci\u00f3n A", "valor": "A"}, {"texto": "Opci\u00f3n B", "valor": "B"}, {"texto": "Opci\u00f3n C", "valor": "C"}, {"texto": "Opci\u00f3n D", "valor": "D"}, {"texto": "Opci\u00f3n E", "valor": "E"}], "respuestaSeleccionada": null, "respuestaCorrectaIndex": 4}, {"numero": 4, "texto": "La Elasticidad en una arquitectura reactiva implica que el sistema puede:\nA) Recuperarse de fallos sin intervenci\u00f3n manual.\nB) Mantener una respuesta oportuna bajo carga variable.\nC) Escalar hacia arriba o hacia abajo autom\u00e1ticamente.\nD) Utilizar programaci\u00f3n funcional para el procesamiento de datos.\nE) Priorizar las tareas cr\u00edticas sobre las menos cr\u00edticas.", "puntaje": 0.5, "opciones": [{"texto": "Opci\u00f3n A", "valor": "A"}, {"texto": "Opci\u00f3n B", "valor": "B"}, {"texto": "Opci\u00f3n C", "valor": "C"}, {"texto": "Opci\u00f3n D", "valor": "D"}, {"texto": "Opci\u00f3n E", "valor": "E"}], "respuestaSeleccionada": null, "respuestaCorrectaIndex": 0}, {"numero": 5, "texto": "\u00bfQu\u00e9 patr\u00f3n de dise\u00f1o se asocia frecuentemente con la implementaci\u00f3n de sistemas reactivos para manejar flujos de datos as\u00edncronos?\nA) Model-View-Controller (MVC)\nB) Observer Pattern\nC) Factory Pattern\nD) Singleton Pattern\nE) Decorator Pattern", "puntaje": 0.5, "opciones": [{"texto": "Opci\u00f3n A", "valor": "A"}, {"texto": "Opci\u00f3n B", "valor": "B"}, {"texto": "Opci\u00f3n C", "valor": "C"}, {"texto": "Opci\u00f3n D", "valor": "D"}, {"texto": "Opci\u00f3n E", "valor": "E"}], "respuestaSeleccionada": null, "respuestaCorrectaIndex": 4}, {"numero": 6, "texto": "\u00bfQu\u00e9 patr\u00f3n se utiliza com\u00fanmente en sistemas reactivos para prevenir fallos en cascada mediante el aislamiento de servicios potencialmente fallidos?\n    A) Patr\u00f3n Command\n    B) Patr\u00f3n Observer\n    C) Circuit Breaker (Cortocircuito)\n    D) Patr\u00f3n Singleton\n    E) Patr\u00f3n Factory", "puntaje": 0.5, "opciones": [{"texto": "Opci\u00f3n A", "valor": "A"}, {"texto": "Opci\u00f3n B", "valor": "B"}, {"texto": "Opci\u00f3n C", "valor": "C"}, {"texto": "Opci\u00f3n D", "valor": "D"}, {"texto": "Opci\u00f3n E", "valor": "E"}], "respuestaSeleccionada": null, "respuestaCorrectaIndex": 4}, {"numero": 7, "texto": "En un sistema reactivo orientado a mensajes, \u00bfcu\u00e1l es una caracter\u00edstica principal de la comunicaci\u00f3n entre componentes?\n    A) Llamadas Directas a M\u00e9todos\n    B) Memoria Compartida\n    C) As\u00edncrona y No Bloqueante\n    D) Transacciones de Base de Datos\n    E) Llamadas a Procedimientos Remotos Bloqueantes", "puntaje": 0.5, "opciones": [{"texto": "Opci\u00f3n A", "valor": "A"}, {"texto": "Opci\u00f3n B", "valor": "B"}, {"texto": "Opci\u00f3n C", "valor": "C"}, {"texto": "Opci\u00f3n D", "valor": "D"}, {"texto": "Opci\u00f3n E", "valor": "E"}], "respuestaSeleccionada": null, "respuestaCorrectaIndex": 4}, {"numero": 8, "texto": "La Elasticidad en los sistemas reactivos se refiere a la capacidad de:\n    A) Manejar fallos de manera elegante\n    B) Responder de manera oportuna\n    C) Mantener la capacidad de respuesta bajo carga variable\n    D) Comunicarse usando mensajes\n    E) Mantener un n\u00famero fijo de instancias", "puntaje": 0.5, "opciones": [{"texto": "Opci\u00f3n A", "valor": "A"}, {"texto": "Opci\u00f3n B", "valor": "B"}, {"texto": "Opci\u00f3n C", "valor": "C"}, {"texto": "Opci\u00f3n D", "valor": "D"}, {"texto": "Opci\u00f3n E", "valor": "E"}], "respuestaSeleccionada": null, "respuestaCorrectaIndex": 2}, {"numero": 9, "texto": "\u00bfCu\u00e1l es un beneficio clave de adoptar una arquitectura reactiva?\n    A) Aumento de la complejidad\n    B) Mayor facilidad para depurar sistemas distribuidos\n    C) Mejora en la utilizaci\u00f3n de recursos y escalabilidad\n    D) Ejecuci\u00f3n secuencial garantizada\n    E) Reducci\u00f3n de la necesidad de monitorizaci\u00f3n", "puntaje": 0.5, "opciones": [{"texto": "Opci\u00f3n A", "valor": "A"}, {"texto": "Opci\u00f3n B", "valor": "B"}, {"texto": "Opci\u00f3n C", "valor": "C"}, {"texto": "Opci\u00f3n D", "valor": "D"}, {"texto": "Opci\u00f3n E", "valor": "E"}], "respuestaSeleccionada": null, "respuestaCorrectaIndex": 1}, {"numero": 10, "texto": "\u00bfQu\u00e9 concepto es fundamental para lograr la Resiliencia en sistemas reactivos?\n    A) Manejo Centralizado de Errores\n    B) Aislamiento y Contenci\u00f3n de Fallos\n    C) Dise\u00f1o con Punto \u00danico de Fallo\n    D) Procesos de Recuperaci\u00f3n Manuales\n    E) Gesti\u00f3n de Estado Global", "puntaje": 0.5, "opciones": [{"texto": "Opci\u00f3n A", "valor": "A"}, {"texto": "Opci\u00f3n B", "valor": "B"}, {"texto": "Opci\u00f3n C", "valor": "C"}, {"texto": "Opci\u00f3n D", "valor": "D"}, {"texto": "Opci\u00f3n E", "valor": "E"}], "respuestaSeleccionada": null, "respuestaCorrectaIndex": 4}], "preguntas_libres": [{"numero": 11, "texto": "Describe c\u00f3mo el principio de \"no bloqueo\" se implementa en un sistema reactivo y proporciona un ejemplo concreto de c\u00f3mo esto beneficia el rendimiento general.", "puntaje": 1, "respuestaAlumno": "", "respuestaProfesor": "## El Principio de \"No Bloqueo\" en Sistemas Reactivos\n\nEl principio de \"no bloqueo\" es fundamental en el dise\u00f1o de sistemas reactivos, asegurando que el sistema permanezca responsivo incluso bajo alta carga o en presencia de operaciones de larga duraci\u00f3n.  Este principio dicta que una operaci\u00f3n no debe bloquear el progreso de otras operaciones. En esencia, se busca evitar que un hilo o proceso quede esperando indefinidamente a que otro termine, liberando as\u00ed recursos y permitiendo que el sistema contin\u00fae procesando otras solicitudes.\n\n**Implementaci\u00f3n del Principio de \"No Bloqueo\":**\n\nLa implementaci\u00f3n del principio de \"no bloqueo\" se logra principalmente mediante las siguientes t\u00e9cnicas:\n\n1. **Asincron\u00eda:**  Las operaciones de larga duraci\u00f3n, como las interacciones con la red o el acceso a disco, se realizan de forma as\u00edncrona. En lugar de esperar a que la operaci\u00f3n complete, el sistema contin\u00faa procesando otras tareas. Cuando la operaci\u00f3n as\u00edncrona finaliza, se notifica al sistema mediante mecanismos como callbacks, promesas o futures.\n\n2. **Programaci\u00f3n basada en eventos:** Los sistemas reactivos se basan en eventos para comunicar la finalizaci\u00f3n de operaciones o la ocurrencia de cambios.  En lugar de un hilo esperar a que otro termine, se registra un \"listener\" o manejador de eventos que se ejecutar\u00e1 cuando el evento correspondiente se produzca. Esto permite que el hilo principal contin\u00fae procesando otros eventos sin bloquearse.\n\n3. **Uso de hilos o procesos ligeros:**  Utilizar m\u00faltiples hilos o, preferiblemente en muchos casos, procesos ligeros (como corrutinas o fibras) permite que diferentes partes del sistema operen concurrentemente.  Mientras un hilo o proceso ligero est\u00e1 bloqueado esperando una operaci\u00f3n I/O, otros pueden continuar procesando solicitudes.  Es crucial gestionar adecuadamente la concurrencia para evitar problemas como condiciones de carrera y bloqueos.\n\n4. **Estructuras de datos no bloqueantes:**  El uso de estructuras de datos dise\u00f1adas espec\u00edficamente para entornos concurrentes y no bloqueantes, como colas concurrentes o variables at\u00f3micas,  permite que m\u00faltiples hilos o procesos ligeros accedan y modifiquen datos compartidos sin necesidad de bloqueos tradicionales, que pueden afectar el rendimiento.\n\n\n**Ejemplo Concreto:**\n\nImaginemos un servidor web que debe atender m\u00faltiples solicitudes de clientes. Si el servidor utiliza un modelo de bloqueo, cada solicitud bloquear\u00eda el hilo principal hasta que se complete la operaci\u00f3n (por ejemplo, leer un archivo del disco o consultar una base de datos).  Esto significa que el servidor no podr\u00eda atender a otros clientes hasta que la solicitud actual finalice, lo que resultar\u00eda en un rendimiento deficiente y una mala experiencia de usuario.\n\nEn cambio, si el servidor implementa el principio de \"no bloqueo\" utilizando asincron\u00eda y un modelo basado en eventos,  puede atender m\u00faltiples solicitudes concurrentemente.  Cuando llega una solicitud que requiere una operaci\u00f3n de larga duraci\u00f3n, el servidor la delega a un hilo o proceso ligero y registra un manejador de eventos.  El hilo principal queda libre para atender otras solicitudes. Cuando la operaci\u00f3n as\u00edncrona finaliza, el manejador de eventos se ejecuta y la respuesta se env\u00eda al cliente.\n\n**Beneficios del Principio de \"No Bloqueo\":**\n\n* **Mayor rendimiento y escalabilidad:** El sistema puede manejar un mayor n\u00famero de solicitudes concurrentes sin degradaci\u00f3n del rendimiento.\n* **Mejor responsividad:** El sistema permanece responsivo incluso bajo alta carga, ya que las operaciones de larga duraci\u00f3n no bloquean el procesamiento de otras solicitudes.\n* **Mayor eficiencia en el uso de recursos:** Se evita el desperdicio de recursos del sistema, como tiempo de CPU, al no mantener hilos bloqueados esperando.\n* **Mejor experiencia de usuario:**  Los usuarios experimentan tiempos de respuesta m\u00e1s r\u00e1pidos y una mayor fluidez en la interacci\u00f3n con el sistema.\n\n\nEn resumen, el principio de \"no bloqueo\" es esencial para construir sistemas reactivos robustos, escalables y responsivos. Su implementaci\u00f3n mediante t\u00e9cnicas como la asincron\u00eda, la programaci\u00f3n basada en eventos y el uso de estructuras de datos no bloqueantes permite maximizar el rendimiento y la eficiencia del sistema, proporcionando una mejor experiencia al usuario.\n"}, {"numero": 12, "texto": "\u00bfC\u00f3mo se manejan los fallos en cascada en una arquitectura reactiva y qu\u00e9 mecanismos espec\u00edficos se utilizan para aislar los fallos y prevenir la propagaci\u00f3n de errores a otros componentes del sistema?", "puntaje": 1, "respuestaAlumno": "", "respuestaProfesor": "## Manejo de Fallos en Cascada en Arquitecturas Reactivas\n\nLas arquitecturas reactivas, basadas en el Manifiesto Reactivo, se dise\u00f1an para ser resilientes a fallos.  Sin embargo, la naturaleza distribuida de estos sistemas introduce el riesgo de fallos en cascada, donde un fallo en un componente puede propagarse r\u00e1pidamente a otros, causando una interrupci\u00f3n generalizada.  Para mitigar este riesgo, se emplean diversos mecanismos de aislamiento y contenci\u00f3n de fallos.\n\n**\u00bfQu\u00e9 son los fallos en cascada?**\n\nUn fallo en cascada ocurre cuando un fallo en un componente del sistema desencadena una serie de fallos en otros componentes interconectados.  Imagine un efecto domin\u00f3, donde la ca\u00edda de una ficha provoca la ca\u00edda de las dem\u00e1s.  En sistemas reactivos, esto puede ocurrir debido a:\n\n* **Dependencias:**  Si un servicio cr\u00edtico falla, los servicios que dependen de \u00e9l tambi\u00e9n pueden fallar.\n* **Sobrecarga:** Un componente sobrecargado puede fallar y, a su vez, sobrecargar otros componentes que intentan comunicarse con \u00e9l, propagando el fallo.\n* **Propagaci\u00f3n de errores:**  Un error no gestionado en un componente puede propagarse a otros componentes a trav\u00e9s de llamadas a funciones o mensajes.\n\n**Mecanismos para Aislar Fallos y Prevenir la Propagaci\u00f3n de Errores:**\n\nLas arquitecturas reactivas utilizan varios mecanismos para abordar los fallos en cascada:\n\n1. **Aislamiento de Fallos (Fault Isolation):**\n\n    * **Bulkheads:**  Similar a los compartimentos estancos de un barco, los bulkheads dividen la aplicaci\u00f3n en grupos de componentes aislados.  Si un grupo falla, los otros permanecen operativos.  Esto limita el impacto de un fallo a un \u00e1rea espec\u00edfica.  Se pueden implementar bulkheads a nivel de hilos, pools de conexiones, y recursos.\n    * **Timeouts:**  Establecen un l\u00edmite de tiempo para la respuesta de un servicio. Si el servicio no responde dentro del timeout, la solicitud se considera fallida.  Esto previene que un componente espere indefinidamente a un servicio que no responde, evitando bloqueos y la propagaci\u00f3n de la sobrecarga.\n    * **Circuit Breakers:**  Act\u00faan como interruptores autom\u00e1ticos.  Monitorean las llamadas a un servicio y, si detecta un n\u00famero excesivo de fallos en un per\u00edodo de tiempo determinado, \"abren el circuito\", impidiendo futuras llamadas al servicio fallido durante un tiempo de \"enfriamiento\".  Esto da tiempo al servicio para recuperarse y evita que el sistema se sobrecargue con solicitudes fallidas.\n\n\n2. **Contenci\u00f3n de Errores (Error Containment):**\n\n    * **Supervisi\u00f3n y registro:**  Un sistema de monitoreo robusto proporciona informaci\u00f3n sobre el estado de los componentes y alerta sobre posibles problemas.  El registro detallado ayuda a rastrear la causa ra\u00edz de los fallos.\n    * **Manejo de excepciones:**  Implementar un manejo de excepciones adecuado en cada componente es crucial para capturar y gestionar errores localmente, evitando que se propaguen a otros componentes.  El uso de estrategias como reintentos, fallback a valores predeterminados o la generaci\u00f3n de eventos de error permite una respuesta controlada a las excepciones.\n    * **Propagaci\u00f3n de backpressure:**  Permite que los componentes downstream comuniquen su capacidad de procesamiento a los componentes upstream.  Si un componente downstream est\u00e1 sobrecargado, puede se\u00f1alar a los componentes upstream que reduzcan la velocidad de env\u00edo de solicitudes, evitando la sobrecarga y los fallos en cascada.\n\n\n3. **Replicaci\u00f3n y Redundancia:**\n\n    * **Instancias M\u00faltiples:**  Ejecutar m\u00faltiples instancias de un servicio proporciona redundancia.  Si una instancia falla, las otras pueden continuar procesando las solicitudes.  Load balancers distribuyen la carga entre las instancias disponibles.\n    * **Replicaci\u00f3n de Datos:**  Replicar datos en m\u00faltiples nodos asegura la disponibilidad de la informaci\u00f3n incluso si un nodo falla.\n\n\n**Ejemplo:**\n\nImaginemos un sistema de comercio electr\u00f3nico.  Si el servicio de pago falla, un bulkhead puede aislar el fallo, permitiendo que otras partes del sistema, como la navegaci\u00f3n del cat\u00e1logo o la gesti\u00f3n del carrito de compras, sigan funcionando.  Un circuit breaker puede evitar que el sistema intente repetidamente procesar pagos a trav\u00e9s del servicio fallido, mientras que un sistema de monitoreo alerta a los administradores sobre el problema.\n\nEn resumen, el manejo de fallos en cascada en arquitecturas reactivas requiere una estrategia multifac\u00e9tica que combine aislamiento de fallos, contenci\u00f3n de errores, replicaci\u00f3n y redundancia.  Al implementar estos mecanismos, se puede construir un sistema resiliente capaz de tolerar fallos individuales sin sufrir interrupciones generalizadas.\n"}, {"numero": 13, "texto": "Analiza las ventajas y desventajas de utilizar un enfoque reactivo para el desarrollo de microservicios, considerando aspectos como la complejidad de la implementaci\u00f3n, la gesti\u00f3n de la consistencia de datos y la observabilidad.", "puntaje": 1, "respuestaAlumno": "", "respuestaProfesor": "## An\u00e1lisis de las Ventajas y Desventajas de un Enfoque Reactivo en el Desarrollo de Microservicios\n\nUn enfoque reactivo en el desarrollo de microservicios se basa en los principios de la programaci\u00f3n reactiva, que promueve sistemas responsivos, resilientes, el\u00e1sticos y orientados a mensajes. Si bien ofrece ventajas significativas, tambi\u00e9n presenta desaf\u00edos que deben considerarse cuidadosamente.\n\n**Ventajas:**\n\n* **Mayor Responsividad y Elasticidad:** Los sistemas reactivos manejan la asincron\u00eda y la concurrencia de forma eficiente, lo que permite responder r\u00e1pidamente a las solicitudes incluso bajo alta carga.  La no-bloqueo inherente a este enfoque facilita el escalado horizontal de los microservicios para adaptarse a las fluctuaciones en la demanda.\n* **Resiliencia Mejorada:** El manejo de fallos se simplifica mediante mecanismos como los circuit breakers y los timeouts, que a\u00edslan los fallos y evitan la propagaci\u00f3n de errores en cascada. La inmutabilidad de los datos y la gesti\u00f3n de eventos contribuyen a la recuperaci\u00f3n r\u00e1pida ante fallos.\n* **Acoplamiento D\u00e9bil entre Microservicios:** La comunicaci\u00f3n as\u00edncrona basada en mensajes reduce el acoplamiento entre microservicios.  Esto facilita la evoluci\u00f3n independiente de cada servicio, permitiendo actualizaciones y despliegues sin afectar a otros componentes del sistema.\n* **Mayor Eficiencia en el Uso de Recursos:** La no-bloqueo permite que los hilos de ejecuci\u00f3n se utilicen de manera m\u00e1s eficiente, evitando el desperdicio de recursos mientras se espera la respuesta de otros servicios. Esto se traduce en un mejor rendimiento y menor consumo de recursos.\n* **Simplicidad en la Gesti\u00f3n de la Concurrencia:** Los frameworks reactivos proporcionan abstracciones para manejar la concurrencia, simplificando el desarrollo y reduciendo la probabilidad de errores relacionados con la sincronizaci\u00f3n.\n\n\n**Desventajas:**\n\n* **Complejidad de la Implementaci\u00f3n:**  Adoptar un enfoque reactivo requiere un cambio de paradigma en la forma de pensar y dise\u00f1ar sistemas. La gesti\u00f3n de la asincron\u00eda, los flujos de datos y la depuraci\u00f3n pueden ser m\u00e1s complejos que en un enfoque tradicional.  La curva de aprendizaje para los desarrolladores puede ser pronunciada.\n* **Gesti\u00f3n de la Consistencia de Datos:**  En un sistema distribuido con comunicaci\u00f3n as\u00edncrona, mantener la consistencia de datos puede ser un desaf\u00edo.  Se requieren estrategias espec\u00edficas como sagas o CQRS para garantizar la integridad de los datos a trav\u00e9s de m\u00faltiples microservicios.\n* **Observabilidad:**  Depurar y monitorizar sistemas reactivos puede ser m\u00e1s complejo debido a la naturaleza as\u00edncrona de las interacciones. Se necesitan herramientas y t\u00e9cnicas espec\u00edficas para rastrear el flujo de datos y diagnosticar problemas.  La gesti\u00f3n de logs y el tracing requieren una planificaci\u00f3n cuidadosa.\n* **Madurez de las Tecnolog\u00edas:** Si bien las tecnolog\u00edas reactivas est\u00e1n ganando popularidad, algunas a\u00fan est\u00e1n en etapas relativamente tempranas de madurez.  Esto puede implicar una menor disponibilidad de documentaci\u00f3n, soporte y bibliotecas en comparaci\u00f3n con enfoques m\u00e1s tradicionales.\n* **Testing:**  Probar sistemas reactivos requiere enfoques diferentes a los utilizados en sistemas s\u00edncronos.  Se necesitan herramientas y frameworks espec\u00edficos para simular eventos as\u00edncronos y verificar el comportamiento del sistema bajo diferentes condiciones de carga.\n\n\n**Conclusi\u00f3n:**\n\nUn enfoque reactivo para el desarrollo de microservicios ofrece ventajas significativas en t\u00e9rminos de responsividad, resiliencia y escalabilidad.  Sin embargo, introduce complejidad en la implementaci\u00f3n, la gesti\u00f3n de la consistencia de datos y la observabilidad.  Es crucial evaluar cuidadosamente las ventajas y desventajas antes de adoptar este enfoque, considerando las necesidades espec\u00edficas del proyecto y la experiencia del equipo de desarrollo.  Una planificaci\u00f3n adecuada, la selecci\u00f3n de las herramientas correctas y una s\u00f3lida estrategia de testing son fundamentales para el \u00e9xito de un proyecto de microservicios reactivos.\n"}, {"numero": 14, "texto": "Dise\u00f1a una estrategia para migrar un sistema monol\u00edtico existente a una arquitectura reactiva, incluyendo los pasos clave, las consideraciones de dise\u00f1o y los posibles desaf\u00edos que se podr\u00edan encontrar durante el proceso.", "puntaje": 1, "respuestaAlumno": "", "respuestaProfesor": "## Migraci\u00f3n de un Sistema Monol\u00edtico a una Arquitectura Reactiva: Una Estrategia Detallada\n\nMigrar un sistema monol\u00edtico a una arquitectura reactiva es un proceso complejo que requiere una planificaci\u00f3n cuidadosa y una ejecuci\u00f3n met\u00f3dica.  No se trata de una simple reescritura, sino de una transformaci\u00f3n gradual que busca mejorar la resiliencia, la escalabilidad y la capacidad de respuesta del sistema.  A continuaci\u00f3n, se presenta una estrategia detallada para abordar esta migraci\u00f3n:\n\n**I. Fase de Evaluaci\u00f3n y Planificaci\u00f3n:**\n\n1. **An\u00e1lisis del Monolito:**  Comprender la arquitectura actual del monolito es crucial.  Identificar los m\u00f3dulos, las dependencias, los flujos de datos y los puntos de congesti\u00f3n.  Utilizar herramientas de profiling y an\u00e1lisis de rendimiento para obtener una visi\u00f3n clara del comportamiento del sistema.\n\n2. **Definici\u00f3n de Objetivos:**  Establecer objetivos claros para la migraci\u00f3n. \u00bfSe busca mejorar la escalabilidad, la resiliencia, la capacidad de respuesta o la mantenibilidad?  Definir m\u00e9tricas para medir el \u00e9xito de la migraci\u00f3n.\n\n3. **Selecci\u00f3n de un Patr\u00f3n Reactivo:**  Existen diversos patrones reactivos como CQRS, Event Sourcing y Sagas.  Seleccionar el patr\u00f3n m\u00e1s adecuado para las necesidades del sistema.\n\n4. **Dise\u00f1o de la Arquitectura Objetivo:**  Definir la arquitectura reactiva objetivo, incluyendo los microservicios, las APIs, los mecanismos de comunicaci\u00f3n (mensajer\u00eda, streaming) y las bases de datos.  Considerar la segregaci\u00f3n de responsabilidades y la autonom\u00eda de los microservicios.\n\n5. **Plan de Migraci\u00f3n Incremental:**  Descomponer la migraci\u00f3n en etapas incrementales.  Priorizar los m\u00f3dulos del monolito que se beneficiar\u00e1n m\u00e1s de la arquitectura reactiva.  Definir un cronograma realista para cada etapa.\n\n**II. Fase de Implementaci\u00f3n:**\n\n1. **Desarrollo de Microservicios Reactivos:**  Implementar los nuevos microservicios utilizando principios reactivos: responsividad, resiliencia, elasticidad y orientaci\u00f3n a mensajes.  Utilizar frameworks y bibliotecas reactivas.\n\n2. **Integraci\u00f3n con el Monolito:**  Implementar mecanismos de integraci\u00f3n entre los nuevos microservicios y el monolito existente.  Utilizar patrones como el \"Strangler Fig Pattern\" para estrangular gradualmente la funcionalidad del monolito.\n\n3. **Pruebas Exhaustivas:**  Realizar pruebas unitarias, de integraci\u00f3n y de sistema para asegurar la correcta funcionalidad y el rendimiento de los nuevos microservicios y la integraci\u00f3n con el monolito.  Implementar pruebas de resiliencia para simular fallos y verificar la capacidad de recuperaci\u00f3n del sistema.\n\n4. **Despliegue Incremental:**  Desplegar los nuevos microservicios de forma incremental, minimizando el impacto en los usuarios.  Utilizar t\u00e9cnicas de despliegue como Blue/Green Deployment o Canary Deployment.\n\n5. **Monitorizaci\u00f3n y Observabilidad:**  Implementar un sistema de monitorizaci\u00f3n y observabilidad para recopilar m\u00e9tricas y logs del sistema.  Utilizar estas herramientas para detectar problemas de rendimiento, errores y comportamientos an\u00f3malos.\n\n**III. Fase de Optimizaci\u00f3n y Mantenimiento:**\n\n1. **Afinamiento del Rendimiento:**  Optimizar el rendimiento de los microservicios y la comunicaci\u00f3n entre ellos.  Identificar y eliminar cuellos de botella.\n\n2. **Refactorizaci\u00f3n Continua:**  Refactorizar el c\u00f3digo de los microservicios para mejorar la mantenibilidad y la escalabilidad.\n\n3. **Actualizaci\u00f3n Tecnol\u00f3gica:**  Mantener las bibliotecas y frameworks reactivos actualizados para aprovechar las nuevas funcionalidades y mejoras de rendimiento.\n\n\n**Consideraciones de Dise\u00f1o:**\n\n* **Comunicaci\u00f3n As\u00edncrona:**  Favorecer la comunicaci\u00f3n as\u00edncrona mediante mensajer\u00eda o streaming para desacoplar los microservicios y mejorar la resiliencia.\n* **Idempotencia:**  Dise\u00f1ar los microservicios para que sean idempotentes, es decir, que puedan procesar el mismo mensaje varias veces sin producir efectos secundarios no deseados.\n* **Manejo de Errores:**  Implementar estrategias robustas de manejo de errores para asegurar la resiliencia del sistema.\n* **Transacciones Distribuidas:**  Utilizar patrones como Sagas para gestionar transacciones distribuidas en un entorno reactivo.\n\n\n**Posibles Desaf\u00edos:**\n\n* **Complejidad:**  La arquitectura reactiva introduce una mayor complejidad en el sistema, especialmente en la gesti\u00f3n de la comunicaci\u00f3n as\u00edncrona y el manejo de errores.\n* **Curva de Aprendizaje:**  Los desarrolladores necesitan adquirir nuevas habilidades y conocimientos para trabajar con frameworks y bibliotecas reactivas.\n* **Pruebas:**  Las pruebas en un entorno reactivo pueden ser m\u00e1s complejas debido a la naturaleza as\u00edncrona de la comunicaci\u00f3n.\n* **Monitorizaci\u00f3n:**  La monitorizaci\u00f3n de un sistema reactivo requiere herramientas y t\u00e9cnicas espec\u00edficas para rastrear el flujo de mensajes y detectar problemas de rendimiento.\n\n\n**Conclusi\u00f3n:**\n\nMigrar un sistema monol\u00edtico a una arquitectura reactiva es un proceso desafiante pero gratificante.  Una planificaci\u00f3n cuidadosa, una ejecuci\u00f3n met\u00f3dica y una atenci\u00f3n constante a los detalles son cruciales para el \u00e9xito de la migraci\u00f3n.  Al seguir una estrategia incremental y abordar los desaf\u00edos de forma proactiva, se puede lograr una transformaci\u00f3n exitosa que mejore significativamente la resiliencia, la escalabilidad y la capacidad de respuesta del sistema.\n"}, {"numero": 15, "texto": "\u00bfC\u00f3mo se implementa la resiliencia en un sistema reactivo y qu\u00e9 mecanismos espec\u00edficos se utilizan para manejar fallos y asegurar la disponibilidad?", "puntaje": 1, "respuestaAlumno": "", "respuestaProfesor": "## Implementando la Resiliencia en Sistemas Reactivos\n\nLa resiliencia en un sistema reactivo se refiere a su capacidad de mantenerse responsivo y funcional ante fallos,  sobrecargas y otros eventos disruptivos.  No se trata de evitar los fallos, sino de aceptarlos como inevitables y dise\u00f1ar el sistema para que pueda recuperarse r\u00e1pidamente y continuar operando, aunque sea con funcionalidad degradada.  La implementaci\u00f3n de la resiliencia en sistemas reactivos se basa en varios mecanismos clave:\n\n**1. Replicaci\u00f3n y Redundancia:**\n\n* **Replicaci\u00f3n de datos:**  M\u00faltiples copias de los datos se mantienen en diferentes nodos o ubicaciones. Si un nodo falla, otro puede tomar el relevo sin p\u00e9rdida de informaci\u00f3n.  Ejemplos incluyen bases de datos distribuidas como Cassandra o sistemas de almacenamiento como HDFS.\n* **Replicaci\u00f3n de servicios:**  Instancias m\u00faltiples del mismo servicio se ejecutan concurrentemente. Un balanceador de carga distribuye las peticiones entre las instancias disponibles. Si una instancia falla, las dem\u00e1s contin\u00faan procesando las solicitudes.  Kubernetes y Docker Swarm son ejemplos de orquestadores que facilitan la replicaci\u00f3n de servicios.\n\n**2. Aislamiento de Fallos:**\n\n* **Compartamentalizaci\u00f3n:** El sistema se divide en componentes aislados. Un fallo en un componente no deber\u00eda propagarse a otros, limitando el impacto del fallo.  Microservicios y el patr\u00f3n Bulkhead son ejemplos de esta estrategia.\n* **Supervisores:**  Procesos dedicados monitorizan la salud de otros componentes. Si un componente falla, el supervisor puede reiniciarlo, escalarlo o tomar otras acciones correctivas.  Erlang/OTP y Akka ofrecen mecanismos robustos de supervisi\u00f3n.\n* **Timeouts y Retries:** Se establecen l\u00edmites de tiempo para las operaciones y se implementan mecanismos de reintento para manejar fallos transitorios, como problemas de red.  Librer\u00edas como Resilience4j y Hystrix ofrecen funcionalidades para gestionar timeouts y reintentos.\n\n**3. Degradaci\u00f3n Graceful:**\n\n* **Disyuntores (Circuit Breakers):**  Impiden que un sistema sobrecargado contin\u00fae enviando solicitudes a un servicio que falla repetidamente.  El disyuntor \"se abre\" temporalmente, evitando una cascada de fallos.  Resilience4j y Hystrix implementan este patr\u00f3n.\n* **Fallback:**  Proporciona una respuesta alternativa o un servicio degradado cuando el servicio principal no est\u00e1 disponible.  Por ejemplo, mostrar contenido en cach\u00e9 en lugar de contenido din\u00e1mico si la base de datos no responde.\n* **Priorizaci\u00f3n y Throttling:**  Prioriza las solicitudes cr\u00edticas y limita la tasa de solicitudes para evitar la sobrecarga del sistema.  Esto permite que el sistema contin\u00fae funcionando, aunque con un rendimiento reducido, durante periodos de alta demanda.\n\n**4. Monitoreo y Observabilidad:**\n\n* **Logging:** Registrar eventos importantes, incluyendo errores y excepciones, para facilitar la identificaci\u00f3n y el diagn\u00f3stico de problemas.\n* **M\u00e9tricas:**  Recolectar datos sobre el rendimiento del sistema, como la latencia, el n\u00famero de errores y la utilizaci\u00f3n de recursos, para identificar posibles problemas antes de que se conviertan en fallos.  Prometheus y Grafana son herramientas populares para el monitoreo y la visualizaci\u00f3n de m\u00e9tricas.\n* **Tracing:**  Rastrear el flujo de una solicitud a trav\u00e9s de diferentes componentes del sistema para identificar cuellos de botella y puntos de fallo.  Jaeger y Zipkin son ejemplos de herramientas de tracing.\n\n\n**En resumen,** la resiliencia en sistemas reactivos se logra mediante una combinaci\u00f3n de estrategias que buscan aislar fallos, replicar componentes cr\u00edticos, degradar el servicio de forma controlada y monitorizar constantemente el estado del sistema.  La elecci\u00f3n de los mecanismos espec\u00edficos depender\u00e1 de los requisitos de disponibilidad, el presupuesto y la complejidad del sistema.  Implementar estas estrategias permite a los sistemas reactivos manejar fallos de forma efectiva, manteniendo la disponibilidad y proporcionando una experiencia de usuario robusta incluso en entornos desafiantes.\n"}], "casos_uso": [{"numero": 16, "descripcion": "Dise\u00f1ar e implementar un componente de ingesta que pueda recibir un volumen masivo y variable de eventos de telemetr\u00eda de forma concurrente, sin bloquear el origen de los datos y aplicando alg\u00fan mecanismo de control de flujo (backpressure) si los sistemas de procesamiento est\u00e1n saturados.", "pregunta": "Desarrolle una soluci\u00f3n para el caso descrito anteriormente", "puntaje": 5, "respuestaAlumno": "", "archivoSubido": false, "respuestaProfesor": "## Soluci\u00f3n para la Ingesta de Eventos de Telemetr\u00eda a Gran Escala\n\nEste problema requiere un dise\u00f1o robusto y escalable para manejar un flujo masivo y variable de eventos de telemetr\u00eda. La soluci\u00f3n propuesta se basa en una arquitectura distribuida que utiliza un broker de mensajes, un mecanismo de backpressure y workers concurrentes para procesar los datos.\n\n**Arquitectura:**\n\n1. **Fuente de Datos (Telemetry Producers):**  Los diversos componentes o sistemas que generan los eventos de telemetr\u00eda.  Estos productores deben ser no bloqueantes, es decir, enviar los eventos y continuar su operaci\u00f3n sin esperar confirmaci\u00f3n del procesamiento.\n\n2. **Broker de Mensajes (e.g., Kafka, RabbitMQ, Redis Streams):** Act\u00faa como un buffer intermedio entre los productores y los consumidores. Permite el desacoplamiento temporal y espacial, manejando la concurrencia y la persistencia de los mensajes.  Elegir el broker adecuado depende de los requisitos espec\u00edficos del sistema (volumen, latencia, persistencia, etc.).\n\n3. **Workers (Consumidores):** Procesan los eventos de telemetr\u00eda recibidos del broker.  Se implementan como procesos o hilos concurrentes para maximizar el throughput.\n\n4. **Sistema de Procesamiento (Backend):**  El destino final de los datos procesados (e.g., base de datos, sistema de almacenamiento, sistema de an\u00e1lisis).\n\n**Mecanismo de Backpressure:**\n\nPara evitar la sobrecarga de los workers y el sistema de procesamiento, se implementa un mecanismo de backpressure. Este mecanismo limita la tasa de ingesta de datos cuando los sistemas downstream est\u00e1n saturados.  Existen varias estrategias:\n\n* **Basado en el Broker:**  Algunos brokers (como Kafka) ofrecen mecanismos de control de flujo incorporados. Se puede configurar para pausar el consumo de mensajes cuando las particiones se llenan.\n* **Basado en la Cola de Workers:**  Se limita el tama\u00f1o de la cola de mensajes que cada worker puede procesar. Cuando la cola est\u00e1 llena, el worker deja de consumir del broker temporalmente.\n* **Basado en M\u00e9tricas:**  Se monitorizan m\u00e9tricas clave del sistema (e.g., uso de CPU, memoria, latencia de procesamiento) y se ajusta la velocidad de consumo en funci\u00f3n de estas m\u00e9tricas.  Se puede implementar utilizando un algoritmo de control de congesti\u00f3n.\n\n\n**Implementaci\u00f3n (Ejemplo conceptual con Python y Kafka):**\n\n```python\n# Productor (Ejemplo simplificado)\nfrom kafka import KafkaProducer\n\nproducer = KafkaProducer(bootstrap_servers='kafka:9092')\nfor event in generate_telemetry_events():\n    future = producer.send('telemetry-topic', event.encode('utf-8'))\n    # As\u00edncrono, no bloquea\n\n# Consumidor (Ejemplo simplificado)\nfrom kafka import KafkaConsumer\n\nconsumer = KafkaConsumer('telemetry-topic',\n                         bootstrap_servers='kafka:9092',\n                         group_id='telemetry-group',\n                         auto_offset_reset='earliest')\n\nfor message in consumer:\n    process_event(message.value.decode('utf-8'))\n    # Implementar l\u00f3gica de backpressure aqu\u00ed, por ejemplo,\n    # monitoreando el tama\u00f1o de una cola interna o m\u00e9tricas del sistema.\n    if queue.full():\n        time.sleep(0.1) # Pausa el consumo temporalmente\n\ndef process_event(event):\n    # L\u00f3gica para procesar el evento y enviarlo al backend.\n    # ...\n```\n\n**Consideraciones Adicionales:**\n\n* **Escalabilidad Horizontal:**  La arquitectura debe ser f\u00e1cilmente escalable agregando m\u00e1s workers y particiones al broker de mensajes.\n* **Tolerancia a Fallos:** Implementar mecanismos de redundancia y recuperaci\u00f3n ante fallos tanto en los productores, el broker como en los consumidores.\n* **Monitoreo:**  Monitorear constantemente el rendimiento del sistema (throughput, latencia, errores) para identificar cuellos de botella y optimizar el rendimiento.\n* **Serializaci\u00f3n:**  Elegir un formato de serializaci\u00f3n eficiente (e.g., Avro, Protobuf) para los eventos de telemetr\u00eda.\n* **Seguridad:**  Implementar medidas de seguridad para proteger los datos en tr\u00e1nsito y en reposo.\n\n\n**Conclusi\u00f3n:**\n\nEsta soluci\u00f3n proporciona una arquitectura robusta y escalable para la ingesta de un volumen masivo y variable de eventos de telemetr\u00eda. El uso de un broker de mensajes, workers concurrentes y un mecanismo de backpressure garantiza un procesamiento eficiente y confiable de los datos, incluso bajo picos de carga. La elecci\u00f3n de las tecnolog\u00edas espec\u00edficas y la implementaci\u00f3n del mecanismo de backpressure depender\u00e1n de los requisitos y restricciones del sistema en particular.  Es crucial monitorizar y ajustar el sistema continuamente para asegurar un rendimiento \u00f3ptimo.\n"}, {"numero": 127, "descripcion": "Crear un m\u00f3dulo de procesamiento de datos que, al recibir la telemetr\u00eda, filtre y transforme los eventos relevantes (ej. errores cr\u00edticos, ca\u00eddas de calidad) y los env\u00ede a un servicio de alertas de forma as\u00edncrona y garantizando la entrega, incluso si el servicio de alertas no est\u00e1 disponible temporalmente.\nSugerencias de herramientas o enfoques: Akka Streams, Project Reactor, Kafka, RabbitMQ, Netty, Vert.x.", "pregunta": "Desarrolle una soluci\u00f3n para el caso descrito anteriormente", "puntaje": 5, "respuestaAlumno": "", "archivoSubido": false, "respuestaProfesor": "## Soluci\u00f3n para el procesamiento de telemetr\u00eda y env\u00edo de alertas\n\nEste dise\u00f1o utiliza Kafka como broker de mensajes para garantizar la entrega de alertas incluso con la indisponibilidad temporal del servicio de alertas.  Akka Streams se emplea para el procesamiento as\u00edncrono y la gesti\u00f3n de la concurrencia.\n\n**Arquitectura:**\n\n1. **Entrada de Telemetr\u00eda:** La telemetr\u00eda se ingesta a trav\u00e9s de un endpoint, que puede ser una API REST, un socket, etc.\n\n2. **Akka Streams Pipeline:** Un pipeline de Akka Streams procesa la telemetr\u00eda en tiempo real.  Este pipeline se divide en las siguientes etapas:\n\n    * **`Source`:** Define la fuente de datos de telemetr\u00eda.\n    * **`Flow (Filtro)`:** Implementa la l\u00f3gica de filtrado para identificar eventos relevantes (errores cr\u00edticos, ca\u00eddas de calidad).  Este filtro utiliza criterios predefinidos o reglas configurables.\n    * **`Flow (Transformaci\u00f3n)`:** Transforma los eventos filtrados en un formato adecuado para el servicio de alertas (ej. JSON con campos espec\u00edficos).\n    * **`Sink (Kafka Producer)`:** Env\u00eda los eventos transformados a un topic de Kafka.\n\n3. **Kafka:** Act\u00faa como un buffer persistente y distribuido para las alertas.  Garantiza la entrega incluso si el servicio de alertas est\u00e1 ca\u00eddo.\n\n4. **Servicio de Alertas (Consumidor Kafka):** Un consumidor Kafka se suscribe al topic y procesa las alertas, envi\u00e1ndolas al sistema de notificaciones correspondiente (email, SMS, etc.).\n\n**Implementaci\u00f3n (Conceptual con Akka Streams y Kafka):**\n\n```scala\nimport akka.kafka.ProducerSettings\nimport akka.kafka.scaladsl.Producer\nimport akka.stream.scaladsl.{Flow, Sink, Source}\nimport org.apache.kafka.clients.producer.ProducerRecord\nimport org.apache.kafka.common.serialization.StringSerializer\nimport spray.json._\n\n// ... (Importaciones necesarias para Kafka y Akka Streams) ...\n\n// Suponiendo un formato JSON para la telemetr\u00eda\ncase class Telemetry(eventType: String, severity: Int, message: String)\nobject TelemetryProtocol extends DefaultJsonProtocol {\n  implicit val telemetryFormat = jsonFormat3(Telemetry)\n}\nimport TelemetryProtocol._\n\n// Configuraci\u00f3n de Kafka Producer\nval producerSettings = ProducerSettings(system, new StringSerializer, new StringSerializer)\n  .withBootstrapServers(\"localhost:9092\") // Ajustar seg\u00fan la configuraci\u00f3n de Kafka\n\n// Fuente de telemetr\u00eda (Ejemplo: desde un archivo)\nval telemetrySource = Source.fromFile(new File(\"telemetry.json\")).map(_.parseJson.convertTo[Telemetry])\n\n// L\u00f3gica de filtrado (Ejemplo: eventos con severidad mayor o igual a 5)\nval filterFlow = Flow[Telemetry].filter(_.severity >= 5)\n\n// L\u00f3gica de transformaci\u00f3n (Ejemplo: formatear a JSON)\nval transformFlow = Flow[Telemetry].map(_.toJson.compactPrint)\n\n// Sink para enviar a Kafka\nval kafkaSink = Producer.plainSink(producerSettings, producerSettings.createKafkaProducer())\n  .contramap[String](message => new ProducerRecord[String, String](\"alerts-topic\", message))\n\n// Conectar el pipeline\nval pipeline = telemetrySource\n  .via(filterFlow)\n  .via(transformFlow)\n  .to(kafkaSink)\n\n// Ejecutar el pipeline\npipeline.run()\n\n// Servicio de alertas (Consumidor Kafka - Implementaci\u00f3n separada)\n// ... (L\u00f3gica para consumir mensajes del topic \"alerts-topic\") ...\n```\n\n**Ventajas de este enfoque:**\n\n* **Asincron\u00eda:** El procesamiento de telemetr\u00eda y el env\u00edo de alertas se realizan de forma as\u00edncrona, evitando bloqueos y maximizando el rendimiento.\n* **Garant\u00eda de entrega:** Kafka asegura que las alertas se entreguen incluso si el servicio de alertas no est\u00e1 disponible temporalmente.\n* **Escalabilidad:**  Akka Streams y Kafka son altamente escalables, permitiendo manejar grandes vol\u00famenes de telemetr\u00eda.\n* **Resiliencia:** Akka Streams proporciona mecanismos de manejo de errores y recuperaci\u00f3n, asegurando la estabilidad del sistema.\n\n**Consideraciones adicionales:**\n\n* **Manejo de errores:** Implementar estrategias de reintento y manejo de errores en el consumidor Kafka.\n* **Monitoreo:**  Monitorear el pipeline de Akka Streams y el estado de Kafka para detectar problemas y optimizar el rendimiento.\n* **Seguridad:**  Configurar la autenticaci\u00f3n y autorizaci\u00f3n en Kafka para proteger la informaci\u00f3n sensible.\n\nEste dise\u00f1o proporciona una soluci\u00f3n robusta y escalable para el procesamiento de telemetr\u00eda y el env\u00edo de alertas, abordando los requisitos de asincron\u00eda, garant\u00eda de entrega y manejo de la indisponibilidad del servicio de alertas.  Se puede adaptar y extender para cubrir necesidades espec\u00edficas de cada caso.\n"}]}, "createdAt": "2025-05-08T09:22:11.678184", "expiration": "2025-05-15T14:22:11.600Z", "publicAccess": true}