{"id": "6b45e031", "examenData": {"id": "327553", "nombreExamen": "Programaci\u00f3n UML", "tipoExamen": "Evaluaci\u00f3n", "fecha": "2025-04-28", "profesor": "Mariela Isabel Camargo Rom\u00e1n", "profesorId": "16MI987", "nombreAlumno": "", "idAlumno": "", "bloqueado": true, "preguntasMarcar": [{"numero": 1, "texto": "\u00bfCu\u00e1l de estos principios NO es parte del Manifiesto Reactivo?  \nA) Responsivo  \nB) Tolerante a fallos  \nC) Basado en componentes  \nD) Orientado a mensajes  \nE) Escalable el\u00e1sticamente", "puntaje": 1, "opciones": [{"texto": "Opci\u00f3n A", "valor": "A"}, {"texto": "Opci\u00f3n B", "valor": "B"}, {"texto": "Opci\u00f3n C", "valor": "C"}, {"texto": "Opci\u00f3n D", "valor": "D"}, {"texto": "Opci\u00f3n E", "valor": "E"}], "respuestaSeleccionada": null, "respuestaCorrectaIndex": 4}, {"numero": 2, "texto": "\u00bfQu\u00e9 patr\u00f3n es com\u00fan en arquitecturas reactivas para manejar flujos de datos?  \nA) Singleton  \nB) Observer  \nC) Factory  \nD) Decorator  \nE) Proxy", "puntaje": 1, "opciones": [{"texto": "Opci\u00f3n A", "valor": "A"}, {"texto": "Opci\u00f3n B", "valor": "B"}, {"texto": "Opci\u00f3n C", "valor": "C"}, {"texto": "Opci\u00f3n D", "valor": "D"}, {"texto": "Opci\u00f3n E", "valor": "E"}], "respuestaSeleccionada": null, "respuestaCorrectaIndex": 4}, {"numero": 3, "texto": "\u00bfQu\u00e9 tecnolog\u00eda se usa com\u00fanmente para implementar sistemas reactivos en Java?  \nA) Spring MVC  \nB) Hibernate  \nC) Reactor  \nD) JSP  \nE) JDBC", "puntaje": 1, "opciones": [{"texto": "Opci\u00f3n A", "valor": "A"}, {"texto": "Opci\u00f3n B", "valor": "B"}, {"texto": "Opci\u00f3n C", "valor": "C"}, {"texto": "Opci\u00f3n D", "valor": "D"}, {"texto": "Opci\u00f3n E", "valor": "E"}], "respuestaSeleccionada": null, "respuestaCorrectaIndex": 2}, {"numero": 4, "texto": "\u00bfQu\u00e9 ventaja ofrece el modelo no bloqueante en sistemas reactivos?  \nA) Mayor consumo de recursos hardware  \nB) Mejor manejo de concurrencia con menos hilos  \nC) Simplificaci\u00f3n de la depuraci\u00f3n de errores  \nD) Compatibilidad con lenguajes est\u00e1ticos  \nE) Reducci\u00f3n de la necesidad de testing", "puntaje": 1, "opciones": [{"texto": "Opci\u00f3n A", "valor": "A"}, {"texto": "Opci\u00f3n B", "valor": "B"}, {"texto": "Opci\u00f3n C", "valor": "C"}, {"texto": "Opci\u00f3n D", "valor": "D"}, {"texto": "Opci\u00f3n E", "valor": "E"}], "respuestaSeleccionada": null, "respuestaCorrectaIndex": 2}, {"numero": 5, "texto": "En una arquitectura reactiva, \u00bfqu\u00e9 significa \"backpressure\"?  \nA) Un mecanismo de cifrado de datos  \nB) Control del flujo para evitar sobrecarga del consumidor  \nC) Una t\u00e9cnica de balanceo de carga  \nD) Un patr\u00f3n de redundancia de servidores  \nE) Un protocolo de autenticaci\u00f3n", "puntaje": 1, "opciones": [{"texto": "Opci\u00f3n A", "valor": "A"}, {"texto": "Opci\u00f3n B", "valor": "B"}, {"texto": "Opci\u00f3n C", "valor": "C"}, {"texto": "Opci\u00f3n D", "valor": "D"}, {"texto": "Opci\u00f3n E", "valor": "E"}], "respuestaSeleccionada": null, "respuestaCorrectaIndex": 1}, {"numero": 6, "texto": "\u00bfCu\u00e1l de los siguientes principios NO pertenece al Manifiesto Reactivo?  \nA) Responsivo  \nB) Escalable  \nC) Monol\u00edtico  \nD) Resiliente  \nE) Orientado a mensajes", "puntaje": 1, "opciones": [{"texto": "Opci\u00f3n A", "valor": "A"}, {"texto": "Opci\u00f3n B", "valor": "B"}, {"texto": "Opci\u00f3n C", "valor": "C"}, {"texto": "Opci\u00f3n D", "valor": "D"}, {"texto": "Opci\u00f3n E", "valor": "E"}], "respuestaSeleccionada": null, "respuestaCorrectaIndex": 4}, {"numero": 7, "texto": "\u00bfQu\u00e9 herramienta se usa com\u00fanmente para implementar backpressure en sistemas reactivos?  \nA) Kafka  \nB) Reactor  \nC) RabbitMQ  \nD) MongoDB  \nE) Docker", "puntaje": 1, "opciones": [{"texto": "Opci\u00f3n A", "valor": "A"}, {"texto": "Opci\u00f3n B", "valor": "B"}, {"texto": "Opci\u00f3n C", "valor": "C"}, {"texto": "Opci\u00f3n D", "valor": "D"}, {"texto": "Opci\u00f3n E", "valor": "E"}], "respuestaSeleccionada": null, "respuestaCorrectaIndex": 2}, {"numero": 8, "texto": "En una arquitectura reactiva, \u00bfqu\u00e9 componente se encarga de manejar fallos y recuperaci\u00f3n?  \nA) Load Balancer  \nB) Circuit Breaker  \nC) API Gateway  \nD) Base de datos relacional  \nE) Servidor web", "puntaje": 1, "opciones": [{"texto": "Opci\u00f3n A", "valor": "A"}, {"texto": "Opci\u00f3n B", "valor": "B"}, {"texto": "Opci\u00f3n C", "valor": "C"}, {"texto": "Opci\u00f3n D", "valor": "D"}, {"texto": "Opci\u00f3n E", "valor": "E"}], "respuestaSeleccionada": null, "respuestaCorrectaIndex": 1}, {"numero": 9, "texto": "\u00bfCu\u00e1l de estos lenguajes es ampliamente usado para programaci\u00f3n reactiva?  \nA) Python  \nB) Java  \nC) HTML  \nD) SQL  \nE) CSS", "puntaje": 1, "opciones": [{"texto": "Opci\u00f3n A", "valor": "A"}, {"texto": "Opci\u00f3n B", "valor": "B"}, {"texto": "Opci\u00f3n C", "valor": "C"}, {"texto": "Opci\u00f3n D", "valor": "D"}, {"texto": "Opci\u00f3n E", "valor": "E"}], "respuestaSeleccionada": null, "respuestaCorrectaIndex": 1}, {"numero": 10, "texto": "\u00bfQu\u00e9 patr\u00f3n permite la comunicaci\u00f3n entre componentes reactivos sin acoplamiento directo?  \nA) Singleton  \nB) Factory  \nC) Pub/Sub  \nD) Decorator  \nE) Proxy", "puntaje": 1, "opciones": [{"texto": "Opci\u00f3n A", "valor": "A"}, {"texto": "Opci\u00f3n B", "valor": "B"}, {"texto": "Opci\u00f3n C", "valor": "C"}, {"texto": "Opci\u00f3n D", "valor": "D"}, {"texto": "Opci\u00f3n E", "valor": "E"}], "respuestaSeleccionada": null, "respuestaCorrectaIndex": 3}], "preguntasLibres": [{"numero": 11, "texto": "**Intermedio**: Compara y contrasta el modelo de actores con el patr\u00f3n Observer en el contexto de las arquitecturas reactivas, destacando ventajas y desventajas de cada enfoque.", "puntaje": 1, "respuestaAlumno": "", "respuestaProfesor": "## Comparaci\u00f3n y Contraste entre el Modelo de Actores y el Patr\u00f3n Observer en Arquitecturas Reactivas\n\nTanto el modelo de actores como el patr\u00f3n Observer son herramientas fundamentales para construir sistemas reactivos, permitiendo la comunicaci\u00f3n as\u00edncrona y la gesti\u00f3n de eventos. Sin embargo, difieren significativamente en su enfoque y granularidad.  Esta respuesta analizar\u00e1 ambos modelos, comparando sus caracter\u00edsticas principales, ventajas y desventajas en el contexto de las arquitecturas reactivas.\n\n**1. Modelo de Actores:**\n\n* **Principio:** El modelo de actores se basa en entidades independientes llamadas \"actores\" que se comunican entre s\u00ed mediante el intercambio de mensajes as\u00edncronos. Cada actor tiene su propio estado y comportamiento, y procesa los mensajes uno a la vez, garantizando la concurrencia sin bloqueos.\n\n* **Ventajas en Arquitecturas Reactivas:**\n    * **Concurrencia inherente:** La naturaleza as\u00edncrona y el aislamiento de los actores simplifican la gesti\u00f3n de la concurrencia y evitan problemas como las condiciones de carrera.\n    * **Tolerancia a fallos:**  La encapsulaci\u00f3n del estado dentro de cada actor y la comunicaci\u00f3n mediante mensajes facilitan el aislamiento de fallos. Un actor que falla no afecta directamente a otros actores. Se pueden implementar mecanismos de supervisi\u00f3n para reiniciar o reemplazar actores fallidos.\n    * **Escalabilidad:** La independencia de los actores permite distribuir la carga de trabajo entre m\u00faltiples nodos de un cl\u00faster, mejorando la escalabilidad del sistema.\n    * **Abstracci\u00f3n:** El modelo de actores proporciona una abstracci\u00f3n de alto nivel para la concurrencia, simplificando el dise\u00f1o y desarrollo de sistemas complejos.\n\n\n* **Desventajas:**\n    * **Complejidad de la gesti\u00f3n de mensajes:**  Dise\u00f1ar un sistema de actores robusto requiere una gesti\u00f3n cuidadosa del flujo de mensajes, incluyendo el manejo de mensajes perdidos o retrasados.\n    * **Depuraci\u00f3n:** Depurar un sistema de actores puede ser m\u00e1s complejo que depurar un sistema tradicional debido a la naturaleza as\u00edncrona de la comunicaci\u00f3n.\n    * **Overhead:** La gesti\u00f3n de actores y el env\u00edo de mensajes pueden introducir cierto overhead en comparaci\u00f3n con enfoques m\u00e1s tradicionales.\n\n\n**2. Patr\u00f3n Observer:**\n\n* **Principio:** El patr\u00f3n Observer define una dependencia uno-a-muchos entre un objeto \"sujeto\" y m\u00faltiples \"observadores\". Cuando el estado del sujeto cambia, notifica a todos sus observadores, quienes pueden reaccionar a la actualizaci\u00f3n.\n\n* **Ventajas en Arquitecturas Reactivas:**\n    * **Simplicidad:** El patr\u00f3n Observer es relativamente simple de implementar y comprender.\n    * **Desacople:**  Promueve el desacople entre el sujeto y sus observadores, lo que facilita la modificaci\u00f3n y el mantenimiento del c\u00f3digo.\n\n\n* **Desventajas:**\n    * **Problemas de concurrencia:** Si m\u00faltiples observadores acceden a recursos compartidos, se pueden producir condiciones de carrera. Es necesario implementar mecanismos de sincronizaci\u00f3n para evitar estos problemas.\n    * **Escalabilidad limitada:** El patr\u00f3n Observer puede tener problemas de escalabilidad cuando el n\u00famero de observadores es muy grande, ya que el sujeto debe notificar a todos ellos.\n    * **Potencial para ciclos de notificaci\u00f3n:** Si los observadores tambi\u00e9n son sujetos, se pueden crear ciclos de notificaci\u00f3n que pueden llevar a un comportamiento inesperado.\n\n\n**3. Comparaci\u00f3n Directa:**\n\n| Caracter\u00edstica | Modelo de Actores | Patr\u00f3n Observer |\n|---|---|---|\n| Granularidad | Fina (cada actor es una unidad independiente) | Gruesa (el sujeto notifica a todos los observadores) |\n| Concurrencia | Inherente | Requiere gesti\u00f3n expl\u00edcita |\n| Tolerancia a fallos | Alta | Depende de la implementaci\u00f3n |\n| Escalabilidad | Alta | Limitada |\n| Complejidad | Mayor | Menor |\n\n\n**Conclusi\u00f3n:**\n\nTanto el modelo de actores como el patr\u00f3n Observer son \u00fatiles en arquitecturas reactivas, pero se adaptan mejor a diferentes escenarios. El modelo de actores es ideal para sistemas altamente concurrentes y tolerantes a fallos, donde la granularidad fina y el aislamiento son cruciales.  El patr\u00f3n Observer es m\u00e1s adecuado para sistemas con un menor grado de concurrencia y donde la simplicidad de implementaci\u00f3n es una prioridad. La elecci\u00f3n entre ambos depende de los requisitos espec\u00edficos del sistema.  En algunos casos, incluso se pueden combinar ambos enfoques para aprovechar las ventajas de cada uno.  Por ejemplo, se podr\u00eda utilizar el modelo de actores para la comunicaci\u00f3n entre componentes principales del sistema, y el patr\u00f3n Observer para la gesti\u00f3n de eventos dentro de un actor individual.\n"}, {"numero": 12, "texto": "**Avanzado**: Analiza c\u00f3mo el \"Backpressure\" maneja problemas de sobrecarga en sistemas reactivos y proporciona un ejemplo pr\u00e1ctico de su implementaci\u00f3n en un framework como Akka o Project Reactor.", "puntaje": 1, "respuestaAlumno": "", "respuestaProfesor": "## Manejo de Sobrecarga en Sistemas Reactivos con Backpressure\n\nEn sistemas reactivos, el backpressure es un mecanismo crucial para manejar la sobrecarga y prevenir la inestabilidad del sistema cuando un productor de datos genera datos m\u00e1s r\u00e1pido de lo que un consumidor puede procesarlos.  Sin un mecanismo de backpressure, el consumidor podr\u00eda verse abrumado, llevando a la p\u00e9rdida de datos, latencia excesiva o incluso fallos del sistema.  El backpressure permite al consumidor controlar el flujo de datos del productor, asegurando que la velocidad de producci\u00f3n se ajuste a la capacidad de procesamiento.\n\n**\u00bfC\u00f3mo funciona el backpressure?**\n\nEl backpressure implementa un mecanismo de retroalimentaci\u00f3n entre el consumidor y el productor.  En lugar de que el productor \"empuje\" datos indiscriminadamente, el consumidor \"solicita\" o \"tira\" datos del productor seg\u00fan su capacidad.  Esta comunicaci\u00f3n bidireccional permite al consumidor se\u00f1alar al productor cu\u00e1ndo reducir la velocidad o detener la producci\u00f3n temporalmente, evitando la sobrecarga.  Existen diferentes estrategias de backpressure:\n\n* **Buffering:**  El consumidor utiliza un buffer para almacenar temporalmente los datos recibidos.  Cuando el buffer se llena, el consumidor deja de solicitar datos hasta que tenga capacidad para procesar m\u00e1s.  Esta estrategia es simple pero puede introducir latencia y requiere recursos de memoria para el buffer.\n* **Control de flujo expl\u00edcito:** El consumidor comunica expl\u00edcitamente al productor la cantidad de datos que puede procesar en un momento dado.  El productor respeta esta solicitud y ajusta su velocidad de producci\u00f3n en consecuencia.  Esta estrategia es m\u00e1s eficiente que el buffering, ya que evita la acumulaci\u00f3n de datos en memoria.\n* **Control de flujo impl\u00edcito:**  Se basa en la naturaleza asincr\u00f3nica de los sistemas reactivos.  El productor solo env\u00eda datos cuando el consumidor est\u00e1 listo para recibirlos.  La velocidad de producci\u00f3n se ajusta autom\u00e1ticamente a la velocidad de consumo.\n\n\n**Ejemplo pr\u00e1ctico con Project Reactor:**\n\nProject Reactor, una implementaci\u00f3n popular del patr\u00f3n Reactive Streams en Java, proporciona mecanismos robustos para implementar backpressure. Veamos un ejemplo utilizando `onBackpressureBuffer` y `onBackpressureDrop`:\n\n```java\nimport reactor.core.publisher.Flux;\n\npublic class BackpressureExample {\n\n    public static void main(String[] args) throws InterruptedException {\n\n        // Productor que genera n\u00fameros del 1 al 10 cada 100ms\n        Flux<Integer> fastProducer = Flux.range(1, 10)\n                .delayElements(java.time.Duration.ofMillis(100));\n\n        // Consumidor lento que procesa un n\u00famero cada 500ms\n        Flux<Integer> slowConsumer = fastProducer\n                //.onBackpressureBuffer(10, i -> System.out.println(\"Buffered: \" + i), BufferOverflowStrategy.DROP_OLDEST)\n                .onBackpressureDrop(i -> System.out.println(\"Dropped: \" + i))\n                .delayElements(java.time.Duration.ofMillis(500));\n\n        slowConsumer.subscribe(i -> System.out.println(\"Processed: \" + i));\n\n        Thread.sleep(5000); // Esperamos para ver el efecto del backpressure\n    }\n}\n\n```\n\nEn este ejemplo:\n\n* `fastProducer` genera n\u00fameros r\u00e1pidamente.\n* `slowConsumer` procesa los n\u00fameros lentamente.\n* `onBackpressureDrop` gestiona el backpressure descartando los elementos que el consumidor no puede procesar a tiempo.  La salida mostrar\u00e1 los elementos \"Dropped\".  Si se descomenta `onBackpressureBuffer` y se comenta `onBackpressureDrop`, se utilizar\u00e1 un buffer de tama\u00f1o 10 para almacenar los elementos hasta que el consumidor pueda procesarlos.  Si el buffer se llena, la estrategia `DROP_OLDEST` descartar\u00e1 los elementos m\u00e1s antiguos.\n\n**Conclusi\u00f3n:**\n\nEl backpressure es fundamental para la estabilidad y resiliencia de los sistemas reactivos.  Permite a los consumidores controlar el flujo de datos de los productores, evitando la sobrecarga y asegurando un procesamiento eficiente.  Frameworks como Project Reactor y Akka proporcionan herramientas y estrategias para implementar backpressure de forma efectiva, adapt\u00e1ndose a diferentes necesidades y escenarios.  La elecci\u00f3n de la estrategia correcta depende de los requisitos espec\u00edficos de la aplicaci\u00f3n, como la tolerancia a la latencia y la p\u00e9rdida de datos.\n"}, {"numero": 13, "texto": "**Intermedio**: Explica el rol de los sistemas de mensajer\u00eda (como Kafka o RabbitMQ) en una arquitectura reactiva y c\u00f3mo garantizan la consistencia eventual en un entorno distribuido.", "puntaje": 1, "respuestaAlumno": "", "respuestaProfesor": "## El Rol de los Sistemas de Mensajer\u00eda en una Arquitectura Reactiva y la Consistencia Eventual\n\nLos sistemas de mensajer\u00eda, como Kafka y RabbitMQ, juegan un papel crucial en la construcci\u00f3n de arquitecturas reactivas, facilitando la comunicaci\u00f3n as\u00edncrona y desacoplada entre diferentes componentes de un sistema distribuido.  Su uso contribuye significativamente a la capacidad de respuesta, resiliencia y elasticidad, caracter\u00edsticas clave de los sistemas reactivos.  Adem\u00e1s, permiten la implementaci\u00f3n de patrones que garantizan la consistencia eventual en entornos donde la consistencia inmediata no es factible o deseable.\n\n**Desacoplando Componentes para la Reactividad:**\n\nEn una arquitectura reactiva, los componentes interact\u00faan mediante el intercambio de mensajes a trav\u00e9s de un sistema de mensajer\u00eda.  Este enfoque desacopla los componentes de las siguientes maneras:\n\n* **Temporal:** El emisor del mensaje no necesita esperar a que el receptor lo procese.  Puede continuar con su operaci\u00f3n, mejorando la latencia y el rendimiento.  El receptor procesa el mensaje cuando est\u00e9 disponible, fomentando la autonom\u00eda.\n* **Espacial:** Los componentes no necesitan conocer la ubicaci\u00f3n f\u00edsica de los dem\u00e1s.  El sistema de mensajer\u00eda act\u00faa como intermediario, simplificando la escalabilidad y la gesti\u00f3n del sistema.\n* **L\u00f3gico:**  Los componentes no necesitan conocer la implementaci\u00f3n interna de los dem\u00e1s.  Solo necesitan entender el formato del mensaje, promoviendo la modularidad y la flexibilidad.\n\n**Consistencia Eventual con Sistemas de Mensajer\u00eda:**\n\nEn un sistema distribuido, garantizar la consistencia inmediata (como en las transacciones ACID) puede ser costoso y afectar el rendimiento.  Los sistemas de mensajer\u00eda permiten implementar la consistencia eventual, donde la consistencia se alcanza en alg\u00fan momento en el futuro, despu\u00e9s de la propagaci\u00f3n de los cambios.  Esto se logra mediante diferentes mecanismos:\n\n* **Patrones de publicaci\u00f3n/suscripci\u00f3n:** Los componentes se suscriben a temas o colas de mensajes relevantes.  Cuando un evento ocurre, se publica un mensaje en el tema correspondiente, y todos los suscriptores lo reciben y procesan as\u00edncronamente.  Esto facilita la propagaci\u00f3n de los cambios a trav\u00e9s del sistema.\n\n* **Manejo de fallos y reintentos:** Los sistemas de mensajer\u00eda ofrecen mecanismos para garantizar la entrega de mensajes incluso en caso de fallos.  Si un receptor no puede procesar un mensaje, el sistema lo retiene y lo reintenta posteriormente. Esto contribuye a la consistencia eventual al asegurar que los mensajes eventualmente se procesen.\n\n* **Ordenamiento de mensajes:** Algunos sistemas de mensajer\u00eda, como Kafka, garantizan el orden de los mensajes dentro de una partici\u00f3n. Esto es crucial para mantener la consistencia eventual en escenarios donde el orden de los eventos es importante.\n\n* **Sagat:** Para transacciones distribuidas m\u00e1s complejas, se pueden implementar patrones como el patr\u00f3n Saga.  Este patr\u00f3n orquesta una secuencia de mensajes y compensaciones para asegurar la consistencia eventual en caso de fallos en alguno de los pasos.  El sistema de mensajer\u00eda facilita la coordinaci\u00f3n y la comunicaci\u00f3n entre los participantes de la saga.\n\n**Kafka vs. RabbitMQ en Arquitecturas Reactivas:**\n\nTanto Kafka como RabbitMQ son sistemas de mensajer\u00eda populares, pero tienen diferentes caracter\u00edsticas que los hacen m\u00e1s adecuados para diferentes escenarios:\n\n* **Kafka:** Se destaca por su alto rendimiento, escalabilidad y capacidad de manejar grandes vol\u00famenes de datos.  Es ideal para streaming de datos y procesamiento de eventos en tiempo real.\n\n* **RabbitMQ:** Ofrece una mayor flexibilidad en t\u00e9rminos de protocolos y patrones de mensajer\u00eda.  Es adecuado para sistemas con requisitos de mensajer\u00eda m\u00e1s complejos y donde la latencia es cr\u00edtica.\n\n**Conclusi\u00f3n:**\n\nLos sistemas de mensajer\u00eda son componentes fundamentales en las arquitecturas reactivas. Facilitan la comunicaci\u00f3n as\u00edncrona, el desacoplamiento de componentes y la implementaci\u00f3n de patrones que garantizan la consistencia eventual en entornos distribuidos. La elecci\u00f3n entre diferentes sistemas de mensajer\u00eda, como Kafka y RabbitMQ, depende de las necesidades espec\u00edficas del sistema, como el volumen de datos, los requisitos de rendimiento y la complejidad de la mensajer\u00eda.  Su correcta implementaci\u00f3n es clave para construir sistemas resilientes, escalables y responsivos.\n"}, {"numero": 14, "texto": "**Avanzado**: Dise\u00f1a una arquitectura reactiva para un sistema de comercio electr\u00f3nico de alta concurrencia, detallando c\u00f3mo abordar\u00edas la gesti\u00f3n de estados, la tolerancia a fallos y la latencia.", "puntaje": 1, "respuestaAlumno": "", "respuestaProfesor": "## Arquitectura Reactiva para un Sistema de Comercio Electr\u00f3nico de Alta Concurrencia\n\nUn sistema de comercio electr\u00f3nico de alta concurrencia requiere una arquitectura robusta y escalable que pueda manejar un gran volumen de usuarios y transacciones simult\u00e1neas sin comprometer el rendimiento ni la disponibilidad. Una arquitectura reactiva, basada en el Manifiesto Reactivo, proporciona un marco ideal para lograr estos objetivos.\n\n**Componentes Clave y su Interacci\u00f3n:**\n\n1. **API Gateway:** Act\u00faa como el punto de entrada \u00fanico para todas las solicitudes de los clientes.  Distribuye las solicitudes a los microservicios apropiados utilizando un balanceador de carga.\n\n2. **Microservicios:** Descomponemos la funcionalidad en microservicios independientes, como gesti\u00f3n de productos, carrito de compras, pedidos, pagos y env\u00edos.  Esto permite el escalado independiente y la tolerancia a fallos. Cada microservicio expone una API reactiva.\n\n3. **Base de Datos Reactiva:** Utilizamos una base de datos NoSQL distribuida y reactiva, como Cassandra o MongoDB, para gestionar los datos de forma eficiente y escalable.  Estas bases de datos ofrecen alta disponibilidad y consistencia eventual.\n\n4. **Mensajer\u00eda Reactiva (Ej: Kafka):**  Los microservicios se comunican entre s\u00ed de forma as\u00edncrona mediante un bus de mensajes reactivo. Esto desacopla los servicios, mejora la resistencia y permite el procesamiento de eventos en tiempo real.\n\n5. **Cach\u00e9 Distribuida (Ej: Redis):**  Almacenamos datos frecuentemente accedidos, como informaci\u00f3n de productos y detalles del usuario, en una cach\u00e9 distribuida para reducir la latencia y la carga en la base de datos.\n\n**Gesti\u00f3n de Estados:**\n\n* **Estado Inmutable:**  Utilizamos un enfoque de estado inmutable para simplificar la gesti\u00f3n de la concurrencia y evitar problemas de consistencia. Cada cambio de estado crea una nueva versi\u00f3n del estado, en lugar de modificar el estado existente.\n* **CQRS (Command Query Responsibility Segregation):** Separamos las operaciones de lectura y escritura en diferentes modelos. Esto permite optimizar cada tipo de operaci\u00f3n de forma independiente y escalarlas seg\u00fan sea necesario.\n* **Event Sourcing:**  Almacenamos cada cambio de estado como un evento en un registro de eventos. Esto proporciona una auditor\u00eda completa y la capacidad de reconstruir el estado a cualquier punto en el tiempo.\n* **Akka o Vert.x:**  Frameworks como Akka o Vert.x, basados en el modelo de actor, son ideales para gestionar el estado dentro de cada microservicio de forma concurrente y eficiente.  Los actores encapsulan el estado y se comunican entre s\u00ed mediante mensajes as\u00edncronos.\n\n**Tolerancia a Fallos:**\n\n* **Replicaci\u00f3n de Microservicios:**  Implementamos m\u00faltiples instancias de cada microservicio para asegurar la disponibilidad en caso de fallo. El balanceador de carga distribuye el tr\u00e1fico entre las instancias disponibles.\n* **Supervisi\u00f3n:** Utilizamos patrones de supervisi\u00f3n, como el ofrecido por Akka, para reiniciar autom\u00e1ticamente los microservicios que fallan.\n* **Circuit Breaker:**  Implementamos circuit breakers para evitar que las fallas en un servicio afecten a otros servicios.  Un circuit breaker interrumpe la comunicaci\u00f3n con un servicio que falla repetidamente y evita la cascada de fallos.\n* **Backpressure:**  Implementamos mecanismos de backpressure para que los servicios puedan manejar la sobrecarga de solicitudes.  Un servicio sobrecargado puede enviar una se\u00f1al a los servicios que lo llaman para que reduzcan la velocidad de env\u00edo de solicitudes.\n\n**Latencia:**\n\n* **Cach\u00e9 Distribuida:**  Utilizamos una cach\u00e9 distribuida para almacenar datos frecuentemente accedidos y reducir la latencia de lectura.\n* **Mensajer\u00eda As\u00edncrona:**  La comunicaci\u00f3n as\u00edncrona entre microservicios reduce el tiempo de respuesta y mejora el rendimiento general.\n* **Optimizaci\u00f3n de la Base de Datos:**  Utilizamos t\u00e9cnicas de optimizaci\u00f3n de la base de datos, como la indexaci\u00f3n y la sharding, para mejorar el rendimiento de las consultas.\n* **CDN (Content Delivery Network):**  Utilizamos una CDN para almacenar contenido est\u00e1tico, como im\u00e1genes y videos, cerca de los usuarios, reduciendo la latencia de acceso.\n\n**Conclusi\u00f3n:**\n\nEsta arquitectura reactiva proporciona una base s\u00f3lida para un sistema de comercio electr\u00f3nico de alta concurrencia. Al utilizar microservicios, mensajer\u00eda as\u00edncrona, una base de datos reactiva y mecanismos de tolerancia a fallos, podemos construir un sistema escalable, resiliente y con baja latencia que puede manejar un gran volumen de usuarios y transacciones. La gesti\u00f3n de estados mediante t\u00e9cnicas como Event Sourcing y CQRS, combinada con frameworks como Akka o Vert.x, asegura la consistencia y la eficiencia en un entorno altamente concurrente.  Esta arquitectura permite al sistema adaptarse a las fluctuaciones en la demanda y mantener un alto nivel de disponibilidad y rendimiento.\n"}], "casosUso": [{"numero": 15, "descripcion": "**Escenario**: Una plataforma de comercio en l\u00ednea necesita manejar picos de demanda durante eventos de ventas flash, garantizando respuestas r\u00e1pidas en la actualizaci\u00f3n de inventario y pedidos.  \n   **Requisitos**: Dise\u00f1ar un sistema reactivo con backpressure para evitar sobrecarga, usando colas de mensajes y patrones como Circuit Breaker para fallos.  \n   **Herramientas**: Spring WebFlux, RabbitMQ, Project Reactor, Resilience4j.", "pregunta": "Desarrolle una soluci\u00f3n para el caso descrito anteriormente", "puntaje": 1, "respuestaAlumno": "", "archivoSubido": false, "respuestaProfesor": "## Soluci\u00f3n para el manejo de picos de demanda en una plataforma de comercio en l\u00ednea\n\nEste dise\u00f1o utiliza Spring WebFlux, RabbitMQ, Project Reactor y Resilience4j para crear un sistema reactivo con backpressure y mecanismos de manejo de fallos para una plataforma de comercio en l\u00ednea durante eventos de ventas flash.\n\n**Arquitectura:**\n\n1. **API Gateway (Spring WebFlux):** Recibe las solicitudes de los clientes (e.g., agregar al carrito, realizar pedido).\n2. **Cola de Mensajes (RabbitMQ):** Act\u00faa como buffer para desacoplar la API Gateway de los servicios backend. Las solicitudes se encolar\u00e1n para su procesamiento as\u00edncrono.\n3. **Servicio de Inventario (Spring WebFlux):** Consume mensajes de la cola, actualiza el inventario y publica eventos de actualizaci\u00f3n de inventario.\n4. **Servicio de Pedidos (Spring WebFlux):** Consume mensajes de la cola, crea pedidos y publica eventos de creaci\u00f3n de pedido.\n5. **Base de Datos:** Almacena informaci\u00f3n de inventario y pedidos.\n\n**Implementaci\u00f3n con Backpressure y Circuit Breaker:**\n\n**1. API Gateway:**\n\n* Utiliza Spring WebFlux para manejar solicitudes de forma no bloqueante.\n* Implementa un `Flux` para publicar mensajes en la cola de RabbitMQ.\n* Configura un `onBackpressureBuffer` con un tama\u00f1o limitado para manejar la sobrecarga inicial.  Si la cola se llena, se puede implementar `onBackpressureDrop`  o `onBackpressureLatest` seg\u00fan la estrategia de manejo de sobrecarga deseada, notificando al usuario del problema.\n* Integra Resilience4j para implementar un Circuit Breaker alrededor de la comunicaci\u00f3n con RabbitMQ.  Esto previene la cascada de fallos si RabbitMQ no est\u00e1 disponible.\n\n\n```java\n// Ejemplo de publicaci\u00f3n con backpressure y Circuit Breaker\nFlux<OrderRequest> orderRequests = ...; // Flujo de solicitudes de pedido\n\norderRequests\n    .onBackpressureBuffer(1000, orderRequest -> log.warn(\"Cola llena, descartando solicitud: {}\", orderRequest), BufferOverflowStrategy.DROP_LATEST)\n    .flatMap(orderRequest ->  Mono.fromSupplier(() -> rabbitTemplate.convertAndSend(\"orderQueue\", orderRequest))\n            .transformDeferred(Resilience4j.monoCircuitBreaker(circuitBreakerRegistry.circuitBreaker(\"rabbitMQ\"))))\n    .subscribe();\n```\n\n**2. Servicio de Inventario y Servicio de Pedidos:**\n\n* Utilizan Spring WebFlux y `@RabbitListener` para consumir mensajes de la cola de forma reactiva.\n* Implementan l\u00f3gica de negocio para actualizar inventario y crear pedidos.\n* Utilizan transacciones para garantizar la consistencia de los datos.\n* Publican eventos de actualizaci\u00f3n de inventario y creaci\u00f3n de pedido a otra cola (opcional) para notificar a otros servicios o sistemas.\n* Implementan Resilience4j para manejar fallos al acceder a la base de datos (e.g., reintentos con `Retry`, Circuit Breaker).\n\n```java\n@RabbitListener(queues = \"orderQueue\")\npublic void processOrder(OrderRequest orderRequest) {\n    Mono.fromSupplier(() ->  inventoryService.updateInventory(orderRequest.getProductId(), orderRequest.getQuantity()))\n        .transformDeferred(Resilience4j.monoRetry(retryRegistry.retry(\"inventoryService\")))\n        .transformDeferred(Resilience4j.monoCircuitBreaker(circuitBreakerRegistry.circuitBreaker(\"inventoryDB\")))\n        .flatMap(inventoryUpdated -> {\n            if (inventoryUpdated) {\n               return orderService.createOrder(orderRequest); // Similar manejo de errores con Retry y Circuit Breaker\n            } else {\n                return Mono.error(new InsufficientInventoryException(\"Inventario insuficiente\"));\n            }\n        })\n        .subscribe();\n}\n```\n\n**3. RabbitMQ:**\n\n* Configura la cola de mensajes con una pol\u00edtica de TTL (Time-To-Live) para mensajes expirados, evitando el procesamiento de pedidos antiguos en caso de alta congesti\u00f3n.\n* Configura la cola con un tama\u00f1o m\u00e1ximo para evitar el consumo excesivo de memoria.\n\n**Beneficios:**\n\n* **Escalabilidad:** El sistema puede manejar picos de demanda gracias a la arquitectura as\u00edncrona y la cola de mensajes.\n* **Resiliencia:** El Circuit Breaker y Retry previenen la cascada de fallos y mejoran la tolerancia a fallos.\n* **Backpressure:**  El sistema controla la sobrecarga y evita que los servicios backend se saturen.\n* **Respuesta r\u00e1pida:** La arquitectura reactiva minimiza la latencia y proporciona una mejor experiencia de usuario.\n\n\n**Consideraciones adicionales:**\n\n* **Monitorizaci\u00f3n:** Implementar monitorizaci\u00f3n para rastrear el rendimiento del sistema, la longitud de la cola y los fallos.\n* **Pruebas:** Realizar pruebas de carga para validar la capacidad del sistema para manejar picos de demanda.\n* **Seguridad:** Implementar medidas de seguridad para proteger la plataforma y los datos de los usuarios.\n\n\nEsta soluci\u00f3n proporciona un enfoque robusto y escalable para manejar picos de demanda en una plataforma de comercio en l\u00ednea. La combinaci\u00f3n de Spring WebFlux, RabbitMQ, Project Reactor y Resilience4j permite crear un sistema reactivo con backpressure y mecanismos de manejo de fallos que garantizan la disponibilidad y el rendimiento durante eventos de alta carga.\n"}, {"numero": 16, "descripcion": "**Escenario**: Un servicio de telemetr\u00eda para veh\u00edculos aut\u00f3nomos debe procesar millones de eventos/segundo (ubicaci\u00f3n, velocidad, fallos) y reaccionar a anomal\u00edas en <100ms.  \n   **Requisitos**: Implementar un flujo de eventos con ventanas de tiempo para agregaci\u00f3n y detecci\u00f3n de anomal\u00edas (ej: velocidad > l\u00edmite).  \n   **Herramientas**: Apache Flink, Kafka Streams, Scala con Akka.", "pregunta": "Desarrolle una soluci\u00f3n para el caso descrito anteriormente", "puntaje": 1, "respuestaAlumno": "", "archivoSubido": false, "respuestaProfesor": "## Soluci\u00f3n para el Servicio de Telemetr\u00eda de Veh\u00edculos Aut\u00f3nomos\n\nEste problema requiere un sistema de procesamiento de flujos de eventos en tiempo real capaz de manejar un alto volumen de datos y detectar anomal\u00edas con baja latencia.  A continuaci\u00f3n, se describe una soluci\u00f3n utilizando Apache Flink, que se adapta bien a estos requisitos, aunque se mencionan alternativas con Kafka Streams y Scala/Akka.\n\n**Arquitectura Propuesta (Apache Flink):**\n\n1. **Ingestion:** Los eventos de telemetr\u00eda (ubicaci\u00f3n, velocidad, fallos) de los veh\u00edculos aut\u00f3nomos se env\u00edan a un cl\u00faster de Kafka. Kafka proporciona la durabilidad y el rendimiento necesarios para manejar el alto volumen de datos.\n\n2. **Procesamiento con Flink:** Un trabajo de Flink consume los eventos de Kafka.  Se utiliza el API de DataStream de Flink para procesar los eventos en tiempo real.\n\n3. **Ventanas de Tiempo:** Se aplican ventanas de tiempo (ej: ventanas deslizantes de 1 segundo con un deslizamiento de 100ms) a la corriente de eventos. Esto permite agregar datos dentro de cada ventana para realizar c\u00e1lculos y detectar anomal\u00edas.\n\n4. **Enriquecimiento de Datos (opcional):**  Se pueden enriquecer los datos de telemetr\u00eda con informaci\u00f3n externa, como l\u00edmites de velocidad basados en la ubicaci\u00f3n del veh\u00edculo, utilizando un `RichAsyncFunction` en Flink.  Esto permite comparar la velocidad del veh\u00edculo con el l\u00edmite de velocidad correspondiente.\n\n5. **Detecci\u00f3n de Anomal\u00edas:** Dentro de cada ventana, se calculan m\u00e9tricas y se detectan anomal\u00edas. Por ejemplo, se puede comparar la velocidad del veh\u00edculo con el l\u00edmite de velocidad o detectar patrones inusuales en los datos de los sensores. Se pueden utilizar diferentes algoritmos de detecci\u00f3n de anomal\u00edas, como promedios m\u00f3viles, desviaci\u00f3n est\u00e1ndar o algoritmos m\u00e1s sofisticados basados en aprendizaje autom\u00e1tico.\n\n6. **Alertas:** Cuando se detecta una anomal\u00eda, se genera una alerta.  Esta alerta se puede enviar a otro sistema, como otro topic de Kafka, una base de datos o un sistema de monitorizaci\u00f3n.\n\n7. **Visualizaci\u00f3n (opcional):** Los datos agregados y las anomal\u00edas detectadas se pueden visualizar en un dashboard para monitorizar el estado de los veh\u00edculos aut\u00f3nomos.\n\n\n**Implementaci\u00f3n con Flink (Scala):**\n\n```scala\nimport org.apache.flink.streaming.api.scala._\nimport org.apache.flink.streaming.api.windowing.time.Time\n// ... otras importaciones\n\ncase class TelemetryEvent(vehicleId: String, timestamp: Long, speed: Double, location: String, faultCode: Option[String])\n\nobject TelemetryProcessing {\n  def main(args: Array[String]): Unit = {\n    val env = StreamExecutionEnvironment.getExecutionEnvironment\n\n    // Fuente de datos Kafka\n    val kafkaSource = env.addSource(new FlinkKafkaConsumer[TelemetryEvent](\n      \"telemetry-topic\",\n      new TelemetryEventDeserializer,\n      properties // Propiedades de Kafka\n    ))\n\n    // Ventanas de tiempo y detecci\u00f3n de anomal\u00edas\n    kafkaSource\n      .keyBy(_.vehicleId)\n      .timeWindow(Time.seconds(1), Time.milliseconds(100))\n      .apply { (key: String, window: TimeWindow, events: Iterable[TelemetryEvent]) =>\n        val avgSpeed = events.map(_.speed).sum / events.size\n        val maxSpeed = events.map(_.speed).max\n\n        // Detectar anomal\u00edas (ej: velocidad > 120)\n        if (maxSpeed > 120) {\n          println(s\"Anomal\u00eda detectada: Veh\u00edculo $key con velocidad $maxSpeed a las ${window.getEnd}\")\n          // Enviar alerta\n        }\n\n        (key, avgSpeed, maxSpeed, window.getEnd)\n      }\n      .print() // Imprimir resultados para pruebas\n\n    env.execute(\"Telemetry Processing\")\n  }\n}\n```\n\n**Alternativas:**\n\n* **Kafka Streams:** Ofrece una alternativa m\u00e1s simple para casos menos complejos, integrando el procesamiento directamente en Kafka.  Sin embargo, Flink ofrece mayor flexibilidad y escalabilidad para escenarios m\u00e1s exigentes.\n\n* **Scala/Akka:** Permite construir un sistema de actores para procesar los eventos.  Akka Streams proporciona un framework para el procesamiento de flujos.  Esta opci\u00f3n ofrece un control m\u00e1s granular, pero requiere mayor esfuerzo de desarrollo y gesti\u00f3n.\n\n**Consideraciones:**\n\n* **Escalabilidad:** Flink y Kafka son altamente escalables y pueden manejar millones de eventos por segundo.\n* **Tolerancia a fallos:** Flink y Kafka ofrecen mecanismos de tolerancia a fallos para garantizar la continuidad del servicio.\n* **Latencia:**  El uso de ventanas de tiempo y el procesamiento en tiempo real de Flink permiten detectar anomal\u00edas con baja latencia (<100ms).\n* **Complejidad:** Flink puede ser m\u00e1s complejo de configurar y operar que Kafka Streams, pero ofrece mayor flexibilidad y potencia.\n\n\nEsta soluci\u00f3n proporciona una base s\u00f3lida para el servicio de telemetr\u00eda de veh\u00edculos aut\u00f3nomos.  Se puede extender y adaptar para cubrir requisitos m\u00e1s espec\u00edficos y complejos.  La elecci\u00f3n entre Flink, Kafka Streams o Scala/Akka depender\u00e1 de los requisitos espec\u00edficos del proyecto y la experiencia del equipo.\n"}]}, "createdAt": "2025-04-28T17:27:03.946073", "expiration": "2025-05-05T22:27:03.898Z", "publicAccess": true}